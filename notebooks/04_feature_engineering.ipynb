{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = '0'> Índice </a>\n",
    "\n",
    "* [**Entorno**](#1)  \n",
    "   * [Librerías](#1d1)  \n",
    "   * [Funciones](#1d2)  \n",
    "   * [Constantes](#1d3)\n",
    "\n",
    "* [**Lectura de datos**](#2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = '1'> Entorno </a>\n",
    "[índice](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = '1d1'> Librerías </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "# from config import data_folder\n",
    "\n",
    "from scipy.stats import kurtosis, trim_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = '1d2'> Funciones </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = '1d3'> Constantes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.cons import data_folder, window_jason, cara_lateral, cara_anterior, cara_interior, cara_sepal, list_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = '2'> Lectura de datos </a>\n",
    "[índice](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyect_path = os.getcwd()\n",
    "data_path = proyect_path + data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_combinaciones = list(itertools.combinations(cara_lateral, 2))\n",
    "anterior_combinaciones = list(itertools.combinations(cara_anterior, 2))\n",
    "interior_combinaciones = list(itertools.combinations(cara_interior, 2))\n",
    "sepal_combinaciones = list(itertools.combinations(cara_sepal, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_combinaciones = list(itertools.combinations(list_signals, 2))\n",
    "all_combinaciones = list(itertools.combinations_with_replacement(list_signals, 2))\n",
    "bisignal_combinaciones = list(itertools.combinations(list_signals, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_combinaciones = [item for item in all_combinaciones if item not in bisignal_combinaciones]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisignals_dict = {\"bisignal_combinaciones\": bisignal_combinaciones,\n",
    "                  \"signal_combinaciones\": signal_combinaciones,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = lectura_carpetas_dict(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi = df_all[\"mi\"]\n",
    "df_sttc_mi = df_all[\"sttc_mi\"]\n",
    "df_sttc = df_all[\"sttc\"]\n",
    "df_other = df_all[\"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de windows\n",
    "import json\n",
    "with open(window_jason, \"r\") as file:\n",
    "    dict_data_jump = json.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_mi = pd.DataFrame({'patient_id' : df_mi.keys(),\n",
    "             'class' : \"mi\",\n",
    "             \"class_id\" : 0})\n",
    "patients_sttc_mi = pd.DataFrame({'patient_id' : df_sttc_mi.keys(),\n",
    "             'class' : \"sttc_mi\",\n",
    "             \"class_id\" : 1})\n",
    "patients_sttc = pd.DataFrame({'patient_id' : df_sttc.keys(),\n",
    "             'class' : \"sttc\",\n",
    "             \"class_id\" : 2})\n",
    "patients_other = pd.DataFrame({'patient_id' : df_other.keys(),\n",
    "             'class' : \"other\",\n",
    "             \"class_id\" : 3})\n",
    "\n",
    "patients_classes = pd.concat([patients_mi, patients_sttc_mi, patients_sttc, patients_other], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = split_train_test_val(patients_classes[\"patient_id\"], patients_classes[\"class\"], sizes = [0.10, 0.20], random_state = 42, stratify = patients_classes[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients = pd.DataFrame({\"patient\" : X_train, \n",
    "              \"class\": y_train,\n",
    "              \"sample\" : \"train\"})\n",
    "test_patients = pd.DataFrame({\"patient\" : X_test, \n",
    "              \"class\": y_test,\n",
    "              \"sample\" : \"test\"})\n",
    "val_patients = pd.DataFrame({\"patient\" : X_val, \n",
    "              \"class\": y_val,\n",
    "              \"sample\" : \"validation\"})\n",
    "patients = pd.concat([train_patients, test_patients, val_patients], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.to_csv(\"output/patients.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_train = patients[(patients[\"sample\"] == \"train\")]\n",
    "patients_test = patients[(patients[\"sample\"] == \"test\")]\n",
    "patients_val = patients[(patients[\"sample\"] == \"validation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_train_mi = patients_train[patients_train[\"class\"] == \"mi\"][\"patient\"].values\n",
    "patients_train_sttc_mi = patients_train[patients_train[\"class\"] == \"sttc_mi\"][\"patient\"].values\n",
    "patients_train_sttc = patients_train[patients_train[\"class\"] == \"sttc\"][\"patient\"].values\n",
    "patients_train_other = patients_train[patients_train[\"class\"] == \"other\"][\"patient\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_train = {patient : df_mi[patient] for patient in patients_train_mi}\n",
    "df_sttc_mi_train = {patient : df_sttc_mi[patient] for patient in patients_train_sttc_mi}\n",
    "df_sttc_train = {patient : df_sttc[patient] for patient in patients_train_sttc}\n",
    "df_other_train = {patient : df_other[patient] for patient in patients_train_other}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACF y PACF lags (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_acf_pacf_train = dict_to_dataframe(genera_df_acf_pacf(df_mi_train, list_signals, apply_diff= True))\n",
    "df_sttc_mi_acf_pacf_train = dict_to_dataframe(genera_df_acf_pacf(df_sttc_mi_train, list_signals, apply_diff= True)) \n",
    "df_sttc_acf_pacf_train = dict_to_dataframe(genera_df_acf_pacf(df_sttc_train, list_signals, apply_diff= True))\n",
    "df_other_acf_pacf_train = dict_to_dataframe(genera_df_acf_pacf(df_other_train, list_signals, apply_diff= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_acf_pacf_train.to_csv(\"output/features/mi_acf_pacf_train.csv\", index = False)\n",
    "df_sttc_mi_acf_pacf_train.to_csv(\"output/features/sttc_mi_acf_pacf_train.csv\", index = False)\n",
    "df_sttc_acf_pacf_train.to_csv(\"output/features/sttc_acf_pacf_train.csv\", index = False)\n",
    "df_other_acf_pacf_train.to_csv(\"output/features/other_acf_pacf_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick distribution seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distribución en picos (seasonal, TFF, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Número total de picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_signals = get_dict_labels(df_mi, list_signals)\n",
    "df_sttc_mi_signals = get_dict_labels(df_sttc_mi, list_signals)\n",
    "df_sttc_signals = get_dict_labels(df_sttc, list_signals)\n",
    "df_other_signals = get_dict_labels(df_other, list_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_seasonal = seasonal_decompose(pd.Series(get_estadisticas(df_mi_signals[\"II\"])[\"mean\"]),period = 100).seasonal\n",
    "sttc_mi_seasonal = seasonal_decompose(pd.Series(get_estadisticas(df_sttc_mi_signals[\"II\"])[\"mean\"]),period = 100).seasonal\n",
    "sttc_seasonal = seasonal_decompose(pd.Series(get_estadisticas(df_sttc_signals[\"II\"])[\"mean\"]),period = 100).seasonal\n",
    "other_seasonal = seasonal_decompose(pd.Series(get_estadisticas(df_other_signals[\"II\"])[\"mean\"]),period = 100).seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_train = {patient : df_mi[patient] for patient in patients_train_mi}\n",
    "df_sttc_mi_train = {patient : df_sttc_mi[patient] for patient in patients_train_sttc_mi}\n",
    "df_sttc_train = {patient : df_sttc[patient] for patient in patients_train_sttc}\n",
    "df_other_train = {patient : df_other[patient] for patient in patients_train_other}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_peak_train = get_dict_serie_summary(df_mi_train, list_signals, 100)\n",
    "df_sttc_mi_peak_train = get_dict_serie_summary(df_sttc_mi_train, list_signals, 100)\n",
    "df_sttc_peak_train = get_dict_serie_summary(df_sttc_train, list_signals, 100)\n",
    "df_other_peak_train = get_dict_serie_summary(df_other_train, list_signals, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mi_peak_train.to_csv(\"output/features/mi_peak_train.csv\", index = False)\n",
    "df_sttc_mi_peak_train.to_csv(\"output/features/sttc_mi_peak_train.csv\", index = False)\n",
    "df_sttc_peak_train.to_csv(\"output/features/sttc_peak_train.csv\", index = False)\n",
    "df_other_peak_train.to_csv(\"output/features/other_peak_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Correlation features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlaciones cruzadas\n",
    "* Promedio de correlaciones por combinación.\n",
    "* Desviación estándar de las correlaciones por combinación.\n",
    "* Máxima y mínima correlación por combinación.\n",
    "* Lag de la máxima correlación por combinación.\n",
    "* Kurtosis.\n",
    "* Promedio de todas las autocorrelaciones de la matriz.\n",
    "* Norma de la matriz.\n",
    "* Número de cruces por cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_train_ccf = genera_dict_comb_ccf(df_mi_train, all_combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_ccf_train = patients_dict_ccf(df_mi_train, all_combinaciones)\n",
    "df_sttc_mi_ccf_train = patients_dict_ccf(df_sttc_mi_train, all_combinaciones)\n",
    "df_sttc_ccf_train = patients_dict_ccf(df_sttc_train, all_combinaciones)\n",
    "df_other_ccf_train = patients_dict_ccf(df_other_train, all_combinaciones)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from dask import delayed, compute\n",
    "\n",
    "# Convertir las llamadas a funciones en tareas diferidas con dask.delayed\n",
    "df_mi_ccf_train = delayed(patients_dict_ccf)(df_mi_train, all_combinaciones)\n",
    "df_sttc_mi_ccf_train = delayed(patients_dict_ccf)(df_sttc_mi_train, all_combinaciones)\n",
    "df_sttc_ccf_train = delayed(patients_dict_ccf)(df_sttc_train, all_combinaciones)\n",
    "df_other_ccf_train = delayed(patients_dict_ccf)(df_other_train, all_combinaciones)\n",
    "\n",
    "# Ejecutar las tareas en paralelo\n",
    "results = compute(df_mi_ccf_train, df_sttc_mi_ccf_train, df_sttc_ccf_train, df_other_ccf_train)\n",
    "\n",
    "# Asignar los resultados a las variables\n",
    "df_mi_ccf_train, df_sttc_mi_ccf_train, df_sttc_ccf_train, df_other_ccf_train = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_combinacion = []\n",
    "bi_combinacion = []\n",
    "for col1, col2 in all_combinaciones:\n",
    "    if col1 == col2:\n",
    "        uni_combinacion.append(col1)\n",
    "    else:\n",
    "        bi_combinacion.append(col1 + \"_\" + col2)\n",
    "dict_combinaciones = {\n",
    "    \"uni_combinacion\": uni_combinacion,\n",
    "    \"bi_combinacion\": bi_combinacion\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi_cff_stats_train = get_dict_ccf_summary(df_mi_ccf_train, dict_combinaciones,)\n",
    "df_sttc_mi_cff_stats_train = get_dict_ccf_summary(df_sttc_mi_ccf_train, dict_combinaciones,)\n",
    "df_sttc_cff_stats_train = get_dict_ccf_summary(df_sttc_ccf_train, dict_combinaciones,)\n",
    "df_other_cff_stats_train = get_dict_ccf_summary(df_other_ccf_train, dict_combinaciones,)\n",
    "\n",
    "df_mi_cff_stats_train.to_csv(\"output/features/mi_cff_stats_train.csv\", index = False)\n",
    "df_sttc_mi_cff_stats_train.to_csv(\"output/features/sttc_mi_cff_stats_train.csv\", index = False)\n",
    "df_sttc_cff_stats_train.to_csv(\"output/features/sttc_cff_stats_train.csv\", index = False)\n",
    "df_other_cff_stats_train.to_csv(\"output/features/other_cff_stats_train.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_mcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
