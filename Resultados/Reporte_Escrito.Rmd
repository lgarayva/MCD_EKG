---
title: "null"
author: "null"
output:
  word_document: default
  html_document:
    df_print: paged
---

Maestría en Ciencia de Datos

Estancia de Investigación


![](/Users/leongaray/Desktop/MCD_EKG/img/general/logo-ITAM.png)

REPORTE

Clasificación de electrocardiogramas con machine learning: un análisis de series temporales y feature engineering

PRESENTA  

**León Garay**  
Clave Única: 148539

\newpage

# 1. Introducción

Las enfermedades cardiovasculares son la principal causa de muerte a nivel mundial, incluso en países con ingresos altos, donde solo el cáncer las supera. Un diagnóstico temprano y preciso mediante un electrocardiograma (EKG) ayuda a prevenir complicaciones graves como el infarto agudo de miocardio.

El electrocardiograma es un estudio no invasivo que registra la actividad eléctrica del corazón. Es fundamental para detectar alteraciones en el ritmo cardíaco, conducción eléctrica y morfología cardíaca.

La interpretación de un EKG requiere experiencia clínica y puede variar entre especialistas. Por ello, se ha buscado desarrollar modelos automatizados de interpretación usando machine learning. El dataset PTB-XL, que tiene más de 21,000 registros validados por cardiólogos, permite explorar estas aplicaciones.

Este proyecto busca desarrollar un modelo de clasificación multiclase de EKG para diferenciar distintas patologías cardíacas, usando ingeniería de variables, análisis de series temporales y algoritmos de machine learning, evaluando su desempeño y utilidad clínica.

\newpage

# 2. Datos

Los datos fueron obtenidos de PTB-XL, el cual es el mayor conjunto de datos clínicos de EKG disponible públicamente hasta la fecha. Estos datos fueron desarrollados para generar modelos de aprendizaje de máquina, con el objetivo de generar un sistema de decisiones automatizado para la interpretación de EKG. Este conjunto de datos fue desarrollado para contrarrestar dos grandes obstáculos que se tenían con datos de EKG:

* No existía un conjunto de datos público para entrenamiento y validación público que pudiera utilizarse para desarrollar los modelos.
* La falta de procedimientos definidos para evaluar los algoritmos.

Los datos de *PTB-XL* fueron registrados mediante dispositivos *Schiller AG* de octubre de 1989 a junio de 1966.

El conjunto de datos tiene las siguientes características:

* Un volumen de 21,837 registros de 12 señales, cada una de 10 segundos, provenientes de 18,885 pacientes.
* Está balanceado respecto al género: 52% hombres y 48% mujeres. 
* Presenta un amplio rango de edades, desde 0 hasta 95 años, con una mediana de 62 y un rango intercuartílico de 22.
* Los electrocardiogramas fueron validados por hasta 2 cardiólogos.
* Los registros incluyen información sobre ritmo, forma y diagnóstico del EKG.
* Los diagnósticos se clasificaron en formato de múltiples etiquetas, organizados en 5 súperclases y 24 subclases.

Para la clasificación de los electrocardiogramas, los diagnósticos se agruparon en cinco súperclases principales, las cuales se describen en la Tabla 1.

| Súperclase | Descripción                 |
|:-----------|:----------------------------|
| NORM       | EKG normal                  |
| CD         | Trastorno de la conducción  |
| MI         | Infarto de miocardio        |
| HYP        | Hipertrofia                 |
| STTC       | Cambios en ST/T             |

**Tabla 1.** Categorías de súperclases para la clasificación de EKG. 

De la Tabla 1 se puede observar que existen cinco súperclases. Para este proyecto, se realizó una modificación en la agrupación de las subclases. La modificación consistió en contemplar las clases MI, STTC, STTC & MI y otros. El objetivo de esta reclasificación fue detectar infartos en los que existe algún cambio en el segmento ST y diferenciarlos de aquellos que no presentan alteraciones.

Los datos fueron adquiridos y procesados mediante el procedimiento que se detalla en la siguiente sección.

### 2.1 Adquisición de datos

1. Las señales se recortaron en segmentos de 10 segundos y se guardaron en un formato comprimido de 400 Hz. Para todas las señales, se usó el estándar de las 12 derivaciones (I, II, III, aVL, aVR, aVF, V1, V2, V3, V4, V5 y V6) con referencia al brazo derecho.
2. Una enfermera registró la información en la base de datos.
3. Cada registro fue interpretado en un 67.13% de manera manual por un cardiólogo, 31.2% de manera automática por un dispositivo de EKG con validaciones posteriores por un cardiólogo y un 1.67% sin reporte inicial.
4. Finalmente, todos los reportes fueron nuevamente anotados de manera manual por un experto basado principalmente en características cuantitativas de las señales.


### 2.2 Procesamiento de datos

Las señales fueron convertidas del formato original a un formato binario con 16 bits de precisión a una resolución de 1 $\mu$ V /LSB. Pasaron por un proceso en el que se eliminaron picos de encendido y apagado en los dispositivos, estos picos se encontraban al inicio y final de los registros. Además, las señales fueron re muestreadas a una señal de 500 Hz, y también se generó una versión de 100 Hz.

\newpage

# 3. Análisis exploratorio y procesamiento

El análisis exploratorio de datos tuvo como objetivo identificar patrones temporales y relaciones entre señales del EKG que pudieran ser útiles para la clasificación de patologías cardíacas, así como evaluar la periodicidad de las señales y su estructura de autocorrelación.

Como primer análisis, se estudiaron las autocorrelaciones (ACF) y autocorrelaciones parciales (PACF) de las series originales. Se calculó la ACF de cada serie individual y del agregado por clase y señal. Posteriormente, se obtuvieron las PACF correspondientes, dividiendo los resultados por clase y por señal para su comparación.

El segundo análisis consistió en evaluar la presencia de raíces unitarias mediante la prueba de Dickey-Fuller, con el objetivo de determinar la estacionariedad de las series. Este análisis fue fundamental, ya que la mayoría de las series resultaron no estacionarias, lo que afectaba el cálculo de la ACF. Al aplicar la primera diferencia, se identificaron patrones más claros en las autocorrelaciones.

El tercer análisis consistió en la descomposición de las series para aislar su componente estacional, con el fin de identificar periodicidades relevantes. A partir de este componente estacional, se detectaron picos recurrentes que posteriormente se emplearon para suavizar las series y eliminar ruido, buscando así revelar patrones temporales más claros.

A diferencia de los análisis anteriores que evaluaban cada señal por separado, el cuarto análisis calculó la correlación cruzada entre pares de señales. Este enfoque tuvo como objetivo identificar relaciones entre diferentes derivaciones. Se realizaron los análisis tanto sobre las series originales como sobre sus promedios.

El quinto análisis fue el promedio de las series con intervalos de desviación estándar. Este análisis se realizó tanto para la serie original como a la suavizada con los resultados obtenidos en el análisis tres.

El sexto análisis que se realizó fue similar al cuatro, a diferencia que para este análisis utilizamos un suavizamiento de las series.

Es importante mencionar que, en este apartado se analizarán únicamente la señal II y la clase MI (infarto de miocardio), ya que las derivaciones de la cara inferior (como II, III y aVF) son las más utilizadas para identificar infartos en la región inferior del corazón.

En la Figura 1 se presenta la organización de las derivaciones del EKG según las distintas caras cardíacas (anterior, lateral, inferior y septal), que serán empleadas en los análisis de correlación cruzada entre señales.

![Figura 1. Representación de las caras del corazón (lateral, inferior, septal, anterior) y sus derivaciones correspondientes del electrocardiograma. \n Fuente: Medical Exam Prep (2020). Understanding Acute Coronary Syndromes. Recuperado de https://www.medicalexamprep.co.uk/understanding-acute-coronary-syndromes/](/Users/leongaray/Desktop/MCD_EKG/img/general/CEKG.png){ width=80% }

## 3.1 Análisis de ACF y PACF

![Figura 2. Gráficas de autocorrelación y autocorrelación parcial de la señal II](/Users/leongaray/Desktop/MCD_EKG/img/acf_pacf/acf_pacf_II.png){ width=50% }

![Figura 3. Gráficas de autocorrelación y autocorrelación parcial de la señal II (30 lags)](/Users/leongaray/Desktop/MCD_EKG/img/acf_pacf/acf_pacf_II_2.png){ width=50% }

De las gráficas de autocorrelación y autocorrelación parcial presentadas en la Figura 2 y la Figura 3, podemos notar que estas no descienden a cero, mientras que las gráficas de autocorrelación parciales sí tienden a decrecer a cero conforme aumentan los retrasos. Este comportamiento indica que existe no estacionariedad en la serie o incluso que existe una raíz unitaria. Que la PACF tienda a cero podría indicar que existe un componente autorregresivo, es decir, la serie podría analizarse con un modelo AR.

Para analizar más a fondo, estudiaremos la existencia de raíces unitarias y de no estacionariedad aplicando diferencias a la serie y aplicando la prueba de Dickey-Fuller.

## 3.2 Raíces unitarias

Realizando la prueba de Dickey-Fuller por señal y por clase obtenemos los siguientes resultados:

| Señal |   MI | STTC MI | STTC | OTHER |
|:-----:|-----:|--------:|-----:|------:|
| AVL   | 0.84 |   0.88  | 0.82 |  0.74 |
| V3    | 0.92 |   0.92  | 0.88 |  0.94 |
| V1    | 0.86 |   0.91  | 0.86 |  0.85 |
| V2    | 0.92 |   0.94  | 0.89 |  0.94 |
| II    | 0.84 |   0.86  | 0.82 |  0.85 |
| V4    | 0.86 |   0.89  | 0.81 |  0.91 |
| V5    | 0.80 |   0.88  | 0.82 |  0.88 |
| V6    | 0.71 |   0.84  | 0.75 |  0.82 |
| III   | 0.81 |   0.87  | 0.73 |  0.68 |
| AVR   | 0.89 |   0.91  | 0.88 |  0.91 |
| AVF   | 0.79 |   0.84  | 0.73 |  0.73 |
| I     | 0.89 |   0.90  | 0.89 |  0.91 |

**Tabla 2.** Porcentaje de series por señal y clase que presentan raíces unitarias, según la prueba de Dickey-Fuller.

De la Tabla 2 podemos observar que, aunque no todas las series presentan raíz unitaria, existe no estacionaridad en la serie lo que afecta en la confiabilidad de las autocorrelaciones y en los supuestos de series de tiempo, por lo que es necesario aplicar una diferencia para volver estacionaria la serie.


| Señal |    MI  | STTC MI |  STTC  | OTHER |
|:-----:|-------:|--------:|-------:|------:|
| AVL   | 0.997  | 1.000   | 0.998  | 1.000 |
| V3    | 1.000  | 1.000   | 1.000  | 1.000 |
| V1    | 1.000  | 1.000   | 1.000  | 1.000 |
| V2    | 1.000  | 1.000   | 1.000  | 1.000 |
| II    | 1.000  | 1.000   | 1.000  | 1.000 |
| V4    | 1.000  | 1.000   | 1.000  | 1.000 |
| V5    | 1.000  | 1.000   | 1.000  | 1.000 |
| V6    | 0.998  | 1.000   | 1.000  | 1.000 |
| III   | 0.997  | 1.000   | 0.998  | 1.000 |
| AVR   | 1.000  | 1.000   | 1.000  | 1.000 |
| AVF   | 0.998  | 1.000   | 1.000  | 1.000 |
| I     | 0.998  | 1.000   | 1.000  | 1.000 |


**Tabla 3.** Porcentaje de series por señal y clase que presentan raíces unitarias después de una diferenciación, según la prueba de Dickey-Fuller.

De la Tabla 3 se observa que, al realizar una segunda prueba para determinar si era necesario aplicar una diferencia adicional, menos del 1% de las series presentó raíz unitaria. Por lo tanto, se concluye que únicamente es necesario aplicar solo una diferencia.

![Figura 4. Gráficas de autocorrelación y autocorrelación parcial de la señal II después de aplicar diferencias](/Users/leongaray/Desktop/MCD_EKG/img/acf_pacf/acf_pacf_II_diff_MI.png){ width=50% }

En la Figura 4, donde se muestra la ACF y PACF después de aplicar una diferencia a la serie, se observa que únicamente las primeras cinco autocorrelaciones de la ACF son significativamente distintas de cero, mientras que la PACF mantiene su comportamiento decreciente hacia cero. Este resultado confirma que la suposición inicial sobre la no estacionariedad de las series y la presencia de un componente autorregresivo era correcta.

## 3.3 Descomposición de la serie

En el análisis de descomposición de la serie, nos enfocamos únicamente en el componente estacional de la serie. Para esto, utilizamos el promedio de la serie para obtener esta descomposición. Una vez obtenido el componente estacional del promedio de las series obtuvimos los saltos dentro de la serie tomando en cuenta un salto por encima de dos desviaciones estándar. Con los saltos identificados, se calculó cada cuántos periodos ocurrían en promedio. Los resultados se presentan en la Tabla 4, donde se observa que, en general, los picos ocurren en promedio cada 46.80 periodos en todas las señales.

| Señal |   MI  | STTC MI | STTC  | OTHER | promedio |  std  |
|:-----:|------:|--------:|------:|------:|---------:|------:|
| AVL   | 48.21 |  33.45  |100.00 | 31.79 |   53.36  | 31.96 |
| V3    |100.00 |  48.84  | 25.21 | 32.55 |   51.65  | 33.71 |
| V1    |100.00 | 100.00  | 25.03 | 50.00 |   68.76  | 37.49 |
| V2    | 33.38 | 100.00  | 50.00 | 50.00 |   58.34  | 28.85 |
| II    | 50.21 |  47.79  | 32.21 | 48.37 |   44.64  |  8.36 |
| V4    | 25.36 |  19.90  |100.00 |100.00 |   61.31  | 44.73 |
| V5    | 24.49 |  24.03  | 19.92 | 31.83 |   25.06  |  4.95 |
| V6    | 25.38 |  24.31  | 33.38 |100.00 |   45.77  | 36.38 |
| III   | 19.69 |  50.37  | 24.36 |100.00 |   48.61  | 36.83 |
| AVR   | 24.49 |  31.55  | 32.21 | 32.28 |   30.13  |  3.78 |
| AVF   | 32.07 |  50.26  | 32.97 | 48.37 |   40.92  |  9.74 |
| I     | 32.97 |  31.55  | 33.69 | 34.21 |   33.11  |  1.16 |


**Tabla 4.** Número de saltos en el componente estacional.

![Figura 5. Gráficas de las tendencias estacionales de la señal II](/Users/leongaray/Desktop/MCD_EKG/img/acf_pacf/seasonal_trend_II.png){ width=50% }

En la Figura 5, donde se muestran las gráficas del componente estacional, se observa que las señales correspondientes a MI presentan menor variabilidad o desviación en comparación con las demás. Además, se identifican tendencias de picos más marcadas en estas señales.

La presencia de estos picos en el componente estacional sugiere que las señales presentan periodicidades asociadas al ritmo cardíaco, lo cual puede reflejar patologías. Esta información se utilizó en la ingeniería de variables para contemplar la periodicidad de cada señal.

## 3.4 Análisis de correlación cruzada

Para el análisis de correlación cruzada analizamos distintas variantes de estas:

* Correlación cruzada de las series originales.
* Correlación cruzada de las series originales con intervalos de desviación estándar.
* Correlación cruzada promedio de las series originales con intervalos de desviación estándar.
* Correlación cruzada del promedio de series con suavizamiento (window 50) e intervalos de desviación estándar.
* Correlación cruzada window particular.
* Correlación cruzada con ventana (window) promedio

Para este estudio realizamos un análisis de las señales de la misma cara con sus respectivas combinaciones.


### 3.4.1 Análisis de correlación cruzada de las series originales

En este primer análisis buscábamos encontrar relaciones entre las señales con respecto a las clases, como ejemplo utilizaremos la cara interior la cual contiene la señal II.

![Figura 6. Gráficas de correlaciones cruzadas entre la señal II y la señal III](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_III.png){ width=50% }

![Figura 7. Gráficas de correlaciones cruzadas entre la señal II y la señal AVF](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_AVF.png){ width=50% }

En las Figuras 6 y 7 se observa que existen correlaciones cruzadas notables en los retrasos -75, 0, 75 y unos picos menores dentro de ese intervalo. Sin embargo, no se identificaron diferencias visuales clara entre las clases.

### 3.4.2 de correlación cruzada de las series originales con intervalos de desviación estándar.

En este segundo análisis estudiamos cómo se comporta el promedio de las correlaciones cruzadas en conjunto con la desviación estándar. 

![Figura 8. Gráficas de correlaciones cruzadas entre la señal II y la señal III con bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_III_sd.png){ width=50% }

![Figura 9. Gráficas de correlaciones cruzadas entre la señal II y la señal AVF con bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_AVF_sd.png){ width=50% }

En las Figuras 8 y 9 se observa que, en promedio, la correlación cruzada alcanza su máximo en el retraso 0. Sin embargo, en los demás retrasos no se evidencia una correlación cruzada significativa.

### 3.4.3 Análisis de correlación cruzada promedio de las series originales con intervalos de desviación estándar.

![Figura 10. Promedio de las correlaciones cruzadas entre la señal II y la señal III con bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_mean_II_III_sd.png){ width=50% }

![Figura 12. Promedio de las correlaciones cruzadas entre la señal II y la señal AVF con bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_mean_II_AVF_sd.png){ width=50% }

En relación con el análisis anterior, en las Figuras 10 y 11 se observa que, en promedio, la correlación cruzada alcanza su máximo en el retraso 0. Sin embargo, en los demás retrasos no se identifica una correlación cruzada significativa.

### 3.4.4 Análisis de correlación cruzada del promedio de series con suavizamiento (window 50) e intervalos de desviación estándar.

Otro análisis realizado fue el análisis de correlación cruzada del promedio de la serie suavizada con una ventana arbitraria de 50 periodos. El objetivo de utilizar un suavizamiento fue eliminar ruido y evaluar patrones generales.

![Figura 12. Promedio de las correlaciones cruzadas entre la señal II y la señal III con suavizado (ventana 50) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_III_sd_smooth_50.png){ width=50% }

![Figura 13. Promedio de las correlaciones cruzadas entre la señal II y la señal AVF con suavizado (ventana 50) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_AVF_sd_smooth_50.png){ width=50% }

En las Figuras 12 y 13 se observa que las gráficas presentan picos similares a los del análisis original, sin que se identifique una diferenciación clara entre clases. Por lo tanto, este suavizado no aporta mejoras visuales evidentes.

### 3.4.5 Análisis de correlación cruzada con suavizamiento particular.

Otro análisis realizado fue el análisis de correlación cruzada utilizando como suavizamiento ventanas con periodos obtenidos en la descomposición de la serie. Este suavizamiento se hizo con los valores particulares de cada señal, al igual que el análisis anterior el objetivo fue eliminar ruido y evaluar patrones generales.

![Figura 14. Promedio de las correlaciones cruzadas entre la señal II y la señal III con suavizado (ventana particular) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_III_sd_smooth_part.png){ width=50% }

![Figura 15. Promedio de las correlaciones cruzadas entre la señal II y la señal AVF con suavizado (ventana particular) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_AVF_sd_smooth_part.png){ width=50% }

En la Figura 14 y en la Figura 15 podemos observar que al utilizar una ventana de suavizamiento particular se obtiene una gráfica de correlación cruzada más suave, y se pueden notar picos en otros puntos además del retraso cero. Sin embargo, en ambos casos tampoco existe una relación clara que permita separar las clases de las señales.

### 3.4.6 Análisis de correlación cruzada con suavizamiento promedio.

El último análisis de suavizamiento que se realizó con las correlaciones cruzadas fue analizar si el promedio de los saltos que encontramos en la descomposición de la serie de todas las clases.

![Figura 16. Promedio de las correlaciones cruzadas entre la señal II y la señal III con suavizado (ventana promedio) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_III_sd_smooth_mean.png){ width=50% }

![Figura 17. Promedio de las correlaciones cruzadas entre la señal II y la señal AVF con suavizado (ventana promedio) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/ccf_II_AVF_sd_smooth_mean.png){ width=50% }

En la Figura 16 y en la Figura 17 podemos notar que aplicar un suavizamiento particular o un promedio nos ayuda a encontrar picos en la gráfica de correlación cruzada que no eran fáciles de ver en la gráfica del promedio de las series. Sin embargo, en ambos casos no encontramos una relación clara que permita separar las clases de las señales.

## 3.5 Análisis de serie con intervalos de desviación estándar

El objetivo de este análisis fue evaluar si existían patrones característicos en las series del EKG al calcular su promedio con intervalos de desviación estándar y aplicar distintos suavizados, con el fin de identificar diferencias entre clases que pudieran ser útiles para la clasificación.

### 3.5.1 Promedio de series con intervalos de desviación estándar.

Se analizó el promedio de las series junto con sus intervalos de desviación estándar, para evaluar si existían diferencias visuales entre clases. Sin embargo, visualmente no se encontraron relaciones claras para separar las clases.

![Figura 18. Gráficas del promedio de la señal II con bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/signal_II_mean.png){ width=50% }

Como se observa en la Figura 18, las señales presentan alta variabilidad y no se logra identificar patrones claros que permitan diferenciar las clases.

## 3.5.2 Análisis de serie con intervalos de desviación estándar con suavizamiento de series

Para este análisis se utilizaron las distintas ventanas de suavizamiento:

* Promedio de series con suavizamiento (window 50) e intervalos de desviación estándar.
* Promedio de series con suavizamiento particular e intervalos de desviación estándar.
* Promedio de series con suavizamiento promedio e intervalos de desviación estándar.

### 3.5.2.1 Promedio de series con suavizamiento (window 50) e intervalos de desviación estándar.

Se analizó el promedio de las series suavizadas con una ventana de 50 periodos junto con sus intervalos de desviación estándar, para evaluar si existían diferencias visuales entre clases. Sin embargo, visualmente no se encontraron relaciones claras para separar las clases.

![Figura 19. Gráficas del promedio de la señal II con suavizado (ventana 50) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/signal_II_mean_smooth.png){ width=50% }

En la Figura 19 se puede observar que con este suavizamiento se elimina parte de la variabilidad de las gráficas. Sin embargo, visualmente no se pueden identificar diferencias claras entre las clases.

### 3.5.2.2 Promedio de series con suavizamiento particular e intervalos de desviación estándar.

Se analizó el promedio de las series suavizadas utilizando una ventana particular para cada señal y clase, con intervalos de desviación estándar, para evaluar si existían diferencias visuales entre clases. Sin embargo, visualmente no se encontraron patrones claros para separar las clases.

![Figura 20. Gráficas del promedio de la señal II con suavizado (ventana particular) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/signal_II_mean_smooth_part.png){ width=50% }

En la Figura 20 se puede observar que con este suavizamiento se elimina parte de la variabilidad de las gráficas. Sin embargo, visualmente no se identificaron relaciones claras entre las clases.

### 3.5.2.3 Promedio de series con suavizamiento promedio e intervalos de desviación estándar.

El último análisis realizado fue el promedio de las series suavizadas con una ventana promedio para cada señal con intervalos de desviación estándar, para evaluar si existían diferencias visuales entre clases. Sin embargo, visualmente no se encontraron relaciones directas para separar las clases.

![Figura 21. Gráficas del promedio de la señal II con suavizado (ventana promedio) y bandas de desviación estándar](/Users/leongaray/Desktop/MCD_EKG/img/ccf/signal_II_mean_smooth_mean.png){ width=50% }

En la Figura 21 se puede observar que con este suavizamiento se elimina parte de la variabilidad de las gráficas. Sin embargo, visualmente no se encontraron patrones que permitan separar las clases.

En resumen, aunque los distintos métodos de suavizado redujeron la variabilidad de las señales, no se encontraron diferencias visuales claras entre clases. Esto sugiere que estos promedios suavizados no contienen información suficiente para separarlos, aunque sus estadísticas se considerarán como posibles variables en el modelo.

\newpage

# 4 Ingeniería de variables

La ingeniería de variables tuvo como objetivo generar variables que capturaran la estructura temporal, la variabilidad y la relación entre señales del EKG, con el fin de generar un modelo de clasificación multiclase. Se generaron variables basadas en autocorrelaciones, estadística descriptiva y correlaciones cruzadas. Además, se aplicó un análisis de componentes principales para reducir dimensionalidad en los datos.

## 4.1 Variables de autocorrelaciones

Para las variables de ACF y PACF, con base en el análisis, se encontró que las primeras 5 autocorrelaciones en promedio eran distintas de cero, por lo que se utilizaron estas autocorrelaciones como variables para el modelo. En total se tenían 12 señales y cada señal se utilizó las primeras 5 ACF y PACF dando en total 12*5*2 = 120 variables de este bloque.

## 4.2 Variables estadísticas de las series

Para las variables de estadísticas de la serie se tomó en cuenta variables como amplitud de las series, intensidad de las series, ratio de las series, promedio en donde se dan los picos en las series en el componente estacional, desviación estándar de las series en el componente estacional y número de picos en las series en el componente estacional. Dando un total de $6*12=72$ variables de estadísticas de la serie.

## 4.3 Variables de correlación cruzada 

Para las variables de la CCF se tomaron en cuenta: el número de cruces por cero; el promedio, máximo, mínimo y desviación estándar de la CCF; el retraso correspondiente al máximo y al mínimo de la CCF; la curtosis de la CCF; la media recortada de la CCF; y la norma de la matriz de la CCF. Dando un total de 78*9+1 = 703 variables del bloque de correlación cruzada.

En donde el número de combinaciones posibles fue de: 



$$\binom{12 + 2 - 1}{2} = 78$$

## 4.4 Análisis de Componentes Principales


Se aplicó PCA sobre el conjunto de variables generadas para reducir la dimensionalidad y evitar la multicolinealidad. Inicialmente se tenían 120+72+703 = 905 variables de todos los bloques. Se seleccionaron los primeros k componentes principales que explicaban al menos el 95% de la varianza. Resultando en 285 componentes principales.

En total, se generaron 285 variables por serie. Estas características se usaron como entrada en los modelos de clasificación. Sin embargo, al aplicar PCA para reducir la dimensionalidad, no se evaluó directamente la importancia de cada variable, ya que los modelos utilizaron las combinaciones de componentes principales.

\newpage

# 5. Modelo

Para el modelado se utilizaron distintas arquitecturas de modelos de aprendizaje de máquina. En el modelado realizamos 3 pruebas: 

* Modelado utilizando ingeniería de variables
* Modelado utilizando los valores de las series dividido en partes la serie (chunks).
* Modelado utilizando ingeniería de variables dividiendo la serie en partes (chunks). 

Los modelos que se utilizaron en estas pruebas fueron los siguientes:

* Logistic Regression
* Random Forest Classifier
* Gradient Boosting Classifier
* Naive Bayes
* XGB Classifier

Para estos modelos se realizó una búsqueda de hiperparámetros con técnicas de grid search a excepción del modelo de XGB Classifier. 

Se utilizaron los siguientes diccionarios en la búsqueda de hiperparámetros:


```

Logistic Regression: 

        {'penalty': ['l2'],
            'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]}


Random Forest Classifier
        {'n_estimators': [100, 350, 500],
             'max_features': ['log2', 'sqrt'],
             'max_depth': [5, 10, 20],
             'min_samples_split': [2, 10, 30],
             'min_samples_leaf': [2, 10, 30]}

Gradient Boosting Classifier
        {'n_estimators': [1,10,100], 
             'learning_rate' : [0.01,0.05,0.1],
             'subsample' : [0.1,0.5,1.0], 
             'max_depth': [5,10,20],
             'min_samples_split': [2, 10, 30],
             'min_samples_leaf': [2, 10, 30],
             'max_features': ['log2', 'sqrt']}

Naive Bayes
        {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]}

XGB Classifier
        {
        'learning_rate': [0.1],
        'n_estimators': [5000, 4000, 10000],
        'eval_metric': ['merror', 'auc'],
        'objective': ['multi:softprob'],
        'early_stopping_rounds': [500, 1000]}
```


Es importante mencionar que por costos computacionales no todas las pruebas se evaluaron con el mismo conjunto de hiperparámetros, en algunos casos se redujo esta búsqueda.


Para la evaluación de modelos tomamos en consideración las métricas de accuracy, recall weighted, F1-score weighted y ROC AUC. Con base en estas métricas se evaluó que modelo que desempeñó de mejor manera. Para los modelos que se dividieron en chunks adicional de estas métricas, tomamos en consideración la moda de las predicciones de los chunks y así obtuvimos las métricas de accuracy, precisión weighted, recall weighted y F1-score weighted.

Las tablas siguientes presentan las métricas obtenidas de los distintos modelos evaluados, con el fin de comparar su desempeño. El análisis detallado de estos resultados se realiza en la sección de Resultados.

## 5.1 Modelado utilizando ingeniería de variables

| Metric             | Logistic Regression | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|:------------------:|--------------------:|-------------------------:|-----------------------------:|------------:|---------------:|
| Accuracy           |               0.53  |                    0.48  |                        0.50  |        0.34 |           0.51 |
| Precision weighted |               0.53  |                    0.48  |                        0.50  |        0.37 |           0.52 |
| F1-score weighted  |               0.53  |                    0.48  |                        0.50  |        0.29 |           0.52 |
| ROC AUC            |               0.79  |                    0.75  |                        0.75  |        0.62 |           0.76 |


**Tabla 6.** Resultados del modelo utilizando ingeniería de variables.

La Tabla 6 muestra los resultados del modelo utilizando ingeniería de variables. Una de las complicaciones que se tenía en esta primera serie de modelos es la cantidad de datos. Esta primera serie de modelos se utilizó un set de entrenamiento del 30% para train, 20% para test y 10% para validación. Sin embargo, nos quedábamos con muy pocos registros ya que la base original es únicamente de 2,400 y 285 variables resultantes del PCA lo que llevaría a modelos con sobreajuste y modelos inestables. Por estas complicaciones se planteó la idea de realizar los modelos fragmentando las series originales. 

Los modelos fragmentando las series en chunks se decidieron utilizar dos cortes, en fragmentos de 100 registros y en fragmentos de 5 registros. Estos fragmentos se eligieron en 100 por ser el número de registros que contemplaba un segundo en la serie y fragmentos de 5 por el análisis de autocorrelaciones, en este análisis observamos que las primeras 5 autocorrelaciones eran significativas.

## 5.2 Modelado utilizando valores de series en chunks de 100

| Metric                  | Logistic Regression | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|:-----------------------:|--------------------:|-------------------------:|-----------------------------:|------------:|---------------:|
| Accuracy                |               0.26  |                    0.49  |                        0.50  |        0.33 |           0.51 |
| Precision weighted      |               0.26  |                    0.48  |                        0.51  |        0.33 |           0.52 |
| F1-score weighted       |               0.26  |                    0.48  |                        0.50  |        0.28 |           0.52 |
| ROC AUC                 |               0.50  |                    0.73  |                        0.75  |        0.59 |           0.77 |
| Accuracy mode           |               0.33  |                    0.57  |                        0.53  |        0.31 |           0.53 |
| Precision weighted mode |               0.34  |                    0.57  |                        0.56  |        0.30 |           0.54 |
| F1-score weighted mode  |               0.34  |                    0.56  |                        0.54  |        0.24 |           0.53 |


**Tabla 7.** Resultados del modelo utilizando segmentación en chunks de 100.

## 5.3 Modelado utilizando valores de series en chunks de 5

| Metric                  | Regresión Logística | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|:-----------------------:|--------------------:|-------------------------:|-----------------------------:|------------:|---------------:|
| Accuracy                |               0.26  |                    0.49  |                        0.47  |        0.33 |           0.51 |
| Precision weighted      |               0.26  |                    0.48  |                        0.49  |        0.33 |           0.52 |
| F1-score weighted       |               0.26  |                    0.48  |                        0.48  |        0.28 |           0.52 |
| ROC AUC                 |               0.50  |                    0.73  |                        0.73  |        0.59 |           0.77 |
| Accuracy mode           |               0.33  |                    0.57  |                        0.51  |        0.31 |           0.53 |
| Precision weighted mode |               0.34  |                    0.57  |                        0.54  |        0.30 |           0.54 |
| F1-score weighted mode  |               0.34  |                    0.56  |                        0.52  |        0.24 |           0.53 |


**Tabla 8.** Resultados del modelo utilizando segmentación en chunks de 5.

## 5.4 Modelado utilizando ingeniería de variables divida las series en chunks de 100

| Metric                   | Logistic Regression | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|--------------------------|---------------------|---------------------------|-------------------------------|-------------|-------------|
| Accuracy                 | 0.52                | 0.53                      | 0.53                          | 0.36        | 0.57           |
| Precision weighted       | 0.53                | 0.54                      | 0.54                          | 0.38        | 0.57           |
| F1-score weighted        | 0.52                | 0.53                      | 0.53                          | 0.34        | 0.57           |
| ROC AUC                  | 0.78                | 0.78                      | 0.79                          | 0.65        | 0.82           |
| Accuracy mode            | 0.55                | 0.55                      | 0.55                          | 0.38        | 0.59           |
| Precision weighted mode  | 0.56                | 0.56                      | 0.57                          | 0.42        | 0.59           |
| F1-score weighted mode   | 0.56                | 0.55                      | 0.56                          | 0.36        | 0.59           |


**Tabla 9.** Resultados del modelo utilizando ingeniería de variables y segmentación en chunks de 100 registros.

## 5.5 Tiempos de ejecución

| Versión                        | Logistic Regression | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|--------------------------------|--------------------:|-------------------------:|-----------------------------:|------------:|---------------:|
| Feature Engineering            |                0.05 |                   3.99   |                     15.85    |       0.03  |          0.65  |
| 100 Chunks                     |                0.40 |                  68.93   |                     72.28    |       0.06  |          3.25  |
| 5 Chunks                       |                0.15 |                  62.35   |                     10.45    |       0.07  |          1.59  |
| Feature Engineering 100 Chunks |                0.13 |                  36.52   |                     40.29    |       0.01  |          1.41  |

**Tabla 10.** Tiempos de ejecución de los modelos.

La Tabla 10 muestra los tiempos de ejecución de los modelos, los cuales se reportan únicamente como referencia comparativa, ya que algunos modelos se realizaron con una versión reducida de la búsqueda de hiperparámetros debido a limitaciones computacionales.

\newpage

# 6. Resultados

En esta sección se presentan los resultados de los modelos de clasificación multiclase desarrollados, comparando su desempeño con diferentes combinaciones de características, chunks de series y arquitecturas de modelos. Se reportan las métricas de accuracy, F1-score y ROC AUC.

El modelo de regresión logística obtuvo un ROC AUC de 0.79 y un accuracy de 0.52. Considerando que el accuracy esperado por azar en un problema multiclase de cuatro categorías balanceadas es de 0.25, este resultado indica que el modelo logró duplicar el desempeño del azar, mostrando que las variables generadas contienen información relevante para la clasificación. Sin embargo, un accuracy de 0.52 es insuficiente para aplicaciones clínicas, donde se requiere una precisión mayor para apoyar decisiones diagnósticas. Una posible causa de esta mejora en el desempeño fue el número limitado de registros y las numerosas variables con las que se entrenó el modelo.

Buscando soluciones a tener una cantidad limitada de registros se optó por dividir el datasets en chunks, es decir, cada serie se dividía en pedazos para poder tener una mayor cantidad de registros. Para esta parte se tomaron dos particiones. La primera partición se tomó el número de retrasos obtenidos en la función de autocorrelación, cinco retrasos, y la segunda partición fue arbitraria de 100 registros, es decir, tomando cada registro como un segundo de la serie.

Para la división de la serie temporal en 5 chunks, el modelo que mostró el mejor desempeño fue el XGB Classifier, con un valor de ROC AUC de 0.767521, accuracy global de 0.51405 y un accuracy promedio por paciente de 0.528926.

Aunque el ROC AUC es ligeramente inferior al obtenido con la regresión logística, el accuracy por paciente es ligeramente superior.

Cabe destacar que, al dividir la serie en chunks, cada uno recibe una predicción individual. Para calcular el accuracy por paciente, se tomó la moda de las predicciones de los chunks correspondientes a cada serie y se comparó con la etiqueta real de dicha serie.

Por otro lado, para la división de la serie temporal en 100 chunks, el modelo que mostró el mejor desempeño fue el XGB Classifier, con un valor de ROC AUC de 0.767521, accuracy global de 0.51405 y un accuracy promedio por paciente de 0.528926.

Otro análisis que se realizó fue aplicar ingeniería de variables a la serie dividida por chunks, en esta parte únicamente se tomó la partición de 100 chunks debido a que la ingeniería de variables no era posible únicamente con 5 valores de la serie.

Para la división de la serie temporal en 100 chunks utilizando ingeniería de variables, el modelo que mostró el mejor desempeño fue el XGB Classifier, con un valor de ROC AUC de 0.824416, accuracy global de 0.573444 y un accuracy promedio por paciente de 0.593361. Dando el mejor desempeño de los modelos probados, superando a todos los modelos tanto en ROC AUC como en accuracy.

| Métrica                        | Ing. variables (LogReg) | 100 chunks (XGB) | 5 chunks (XGB) | 100 chunks + ing. variables (XGB) |
|-------------------------------|--------------------------|------------------|----------------|--------------------------------|
| Accuracy                      | 0.53                     | 0.51             | 0.41           | 0.57                              |
| Precision Weighted            | 0.53                     | 0.52             | 0.40           | 0.57                              |
| Recall Weighted               | 0.53                     | 0.51             | 0.41           | 0.57                              |
| F1-score Weighted             | 0.53                     | 0.52             | 0.40           | 0.57                              |
| ROC AUC OVR                   | 0.79                     | 0.77             | 0.67           | 0.82                              |
| Accuracy (mode)               | -                        | 0.53             | 0.51           | 0.59                              |
| Precision Weighted (mode)     | -                        | 0.54             | 0.51           | 0.59                              |
| Recall Weighted (mode)        | -                        | 0.53             | 0.51           | 0.59                              |
| F1-score Weighted (mode)      | -                        | 0.53             | 0.47           | 0.59                              |
                                |


**Tabla 11.** Métricas modelos ganadores.

En la Tabla 11 se comparan los cuatro pipelines previamente descritos: ingeniería de variables, 100 chunks, 5 chunks y 100 chunks con ingeniería de variables. Se observa que el modelo con mejor desempeño fue XGBoost con el enfoque de 100 chunks combinado con ingeniería de variables, obteniendo un accuracy de 0.57 y un ROC AUC de 0.82.

La siguiente tabla muestra la matriz de confusión del modelo ganador. Se puede observar cuántas veces el modelo acertó en cada clase y en cuáles se equivocó más.

|                 | Pred MI | Pred OTHER | Pred STTC | Pred STTC & MI |
|:----------------|--------:|-----------:|----------:|---------------:|
| Real MI         |     314 |        107 |       64  |            115 |
| Real OTHER      |      89 |        409 |       85  |             17 |
| Real STTC       |      90 |         61 |      327  |            132 |
| Real STTC & MI  |     115 |         17 |      136  |            332 |

**Tabla 12.** Matriz de confusión modelo ganador.

De la Tabla 12 se podemos notar lo siguiente:

* La clase MI fue correctamente clasificada en 314 ocasiones; los principales errores se presentaron con la clase OTHER y con la clase STTC & MI.
* La clase OTHER fue la que presentó el mejor desempeño del modelo, con 409 clasificaciones correctas.
* La clase STTC tuvo 327 clasificaciones correctas; los principales errores se dieron con la clase MI y la clase STTC & MI.
* La clase STTC & MI se clasificó correctamente en 332 casos; los principales errores ocurrieron en la clase MI y la clase STTC.

Es importante mencionar que la clase STTC & MI combina las clases STTC y MI, por lo que algunos de los errores de clasificación podrían deberse a que comparten características similares y están clínicamente relacionadas.

| **Clase**    | **Sensibilidad (%)** | **Especificidad (%)** |
|--------------|----------------------|-----------------------|
| **MI**       | 52.3                 | 83.7                  |
| **OTHER**    | 68.2                 | 89.8                  |
| **STTC**     | 53.6                 | 84.2                  |
| **STTC & MI**| 55.3                 | 85.4                  |

**Tabla 13.** Sensibilidad y especificidad por clase en el modelo ganador. La sensibilidad indica la proporción de casos correctamente identificados por clase, mientras que la especificidad representa la proporción de no casos correctamente clasificados. Estas métricas son relevantes para evaluar el desempeño diagnóstico de cada categoría en aplicaciones clínicas.

En la Tabla 13 se muestran las métricas de sensibilidad y especificidad por clase para el modelo ganador. La clase OTHER tuvo la mayor sensibilidad (68.2%) y especificidad (89.8%), indicando que el modelo identifica correctamente a los registros normales o con patologías distintas. La clase MI es la que presentó la menor sensibilidad (52.3%) y especificidad (83.7%). Las clases STTC y STTC & MI mostraron sensibilidades (53.6%-55.3%) y especificidad (84.2%-85.4%) similares. Estos resultados sugieren que el modelo logra un desempeño aceptable en la clasificación general; sin embargo, es necesario optimizar la sensibilidad en las clases de mayor relevancia clínica, como la clase MI, para su aplicación como herramienta de apoyo diagnóstico.

Otro punto importante son los tiempos de entrenamiento de los modelos. En la Tabla 10 se ve que los primeros modelos que usaban solo ingeniería de variables tuvieron tiempos de entrenamiento más bajos en arquitecturas avanzadas, aunque tenían menos datos. También destaca que los modelos XGB con segmentación tuvieron el mejor rendimiento y menor tiempo de entrenamiento frente a otras arquitecturas, aunque solo se entrenaron con una selección de hiperparámetros.

\newpage

# 7. Conclusiones

El objetivo de este proyecto fue crear un modelo que pudiera clasificar diferentes enfermedades cardíacas usando las señales de EKG del dataset PTB-XL, aplicando ingeniería de variables, separación por segmentos y algoritmos de machine learning.

Para este proyecto se generaron 905 variables por serie, incluyendo estadísticas descriptivas, autocorrelaciones y correlaciones cruzadas. Posteriormente se redujo la dimensionalidad usando componentes principales, quedando 209 variables finales. Se evaluaron varios modelos de clasificación y XGBoost fue el que tuvo mejor desempeño, con un ROC AUC de 0.57, accuracy de 0.50 y F1-score macro de 0.47.

Los resultados obtenidos indican que las variables generadas aportan información útil para la clasificación de EKG. Sin embargo, el desempeño de los modelos no alcanza niveles clínicamente aceptables, posiblemente debido a la pérdida de interpretabilidad y varianza explicada al aplicar PCA. Esta reducción en el desempeño sugiere que la selección de variables más relevantes, en lugar de un PCA global, podría mejorar la precisión y facilitar la interpretación médica.

También se observó que el modelo de XGBoost con segmentación e ingeniería de variables no solo obtuvo el mejor desempeño, sino que además presentó tiempos de entrenamiento bajos en comparación con otras arquitecturas. Sin embargo, debido a limitaciones computacionales, los modelos se entrenaron utilizando un número reducido de hiperparámetros, lo que podría haber limitado su optimización completa. Este resultado sugiere que XGBoost es una opción eficiente y viable para este problema, aunque se recomienda realizar una búsqueda de hiperparámetros más exhaustiva en futuros trabajos.

Las principales limitaciones de este proyecto fueron la cantidad limitada de recursos y las restricciones computacionales. Debido a esto, se decidió trabajar con una segmentación arbitraria de los registros, sin considerar intervalos fisiológicos como ciclos cardiacos completos, lo que podría afectar la interpretación clínica de los resultados. Además, aunque se redujo la dimensionalidad aplicando PCA, esto limitó la interpretación de los componentes, ya que se pierde la información sobre qué variables originales aportan más a la separación de clases.

Para trabajos futuros se recomienda probar modelos de deep learning con arquitecturas diseñadas para series de tiempo, y también explorar la extracción de características en el dominio de frecuencia y la morfología de las ondas EKG. De forma alternativa crear cuatro modelos distintos, cada uno entrenado para clasificar una clase específica frente a las demás (enfoque one-vs-all).

En conclusión, este proyecto permitió desarrollar habilidades avanzadas para analizar series de tiempo y modelar señales biomédicas. A pesar de que los resultados todavía no se pueden usar en la práctica clínica, son un primer paso hacia la creación de modelos automáticos de diagnóstico por EKG enfocados a apoyar cardiólogos y ayudar a prevenir eventos cardiovasculares graves con diagnósticos más rápidos y precisos.

\newpage

# 8. Bibliografía

* Wagner, P., Strodthoff, N., Bousseljot, R.-D., Kreiseler, D., Lunze, F. I., Samek, W., … Schaeffter, T. (2020). PTB‑XL, a large publicly available electrocardiography dataset. Scientific Data, 7, 154. https://doi.org/10.1038/s41597-020-0495-6 

* Dubin, D. (2003). Electrocardiografía práctica: Lesionales, trazado e interpretación (3.ª ed.). McGraw-Hill Interamericana.

* Guerrero, V. M. (1993). Análisis estadístico de series de tiempo económicas. Limusa.

* Box, G. E. P., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). Time series analysis: Forecasting and control (5th ed.). Wiley.

* Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: Data mining, inference, and prediction (2nd ed.). Springer.

* Medical Exam Prep. (2020, 10 de septiembre). Understanding acute coronary syndromes. Recuperado de https://www.medicalexamprep.co.uk/understanding-acute-coronary-syndromes/

* Auffarth, B. (2021). Machine learning for time-series with Python: Forecast, predict, and detect anomalies with state-of-the-art machine learning methods. Packt Publishing.

* Guadalajara Boo, J. F. (2012). Cardiología (7.ª ed.). Coyoacán, Ciudad de México: Mendez Editores. 

\newpage

# 9. Repositorio

Todo el código desarrollado para este proyecto se encuentra disponible en el repositorio de GitHub:

https://github.com/lgarayva/MCD_EKG

En este repositorio se documenta detalladamente el uso de cada archivo, el orden de ejecución de los notebooks y las instrucciones para recrear el ambiente de desarrollo, con el fin de garantizar su correcta reproducción y facilitar su implementación.

<!--
# 8. Anexo resultados modelos

## 8.1 Modelado utilizando ingeniería de variables

| metric              | Logistic Regression | Random Forest Classifier | Gradient Boosting Classifier | Naive Bayes | XGB Classifier |
|---------------------|---------------------:|--------------------------:|-----------------------------:|------------:|---------------:|
| accuracy            |             0.527083 |                 0.483333 |                    0.5       |     0.335417 |       0.514583 |
| precision_weighted  |             0.528874 |                 0.481121 |                    0.501884  |     0.374984 |       0.516245 |
| recall_weighted     |             0.527083 |                 0.483333 |                    0.5       |     0.335417 |       0.514583 |
| f1_weighted         |             0.527638 |                 0.48103  |                    0.500224  |     0.287205 |       0.515084 |
| roc_auc_ovr         |             0.790475 |                 0.751476 |                    0.751817  |     0.616916 |       0.762303 |

### 8.1.1 Logistic Regression

| parámetro   | valor   |
|:------------|:--------|
| C           | 0.001   |
| penalty     | l2      |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.487395 | 0.483333 |   0.485356 | 120        |
| 1            |    0.612613 | 0.566667 |   0.588745 | 120        |
| 2            |    0.475806 | 0.491667 |   0.483607 | 120        |
| 3            |    0.539683 | 0.566667 |   0.552846 | 120        |
| accuracy     |    0.527083 | 0.527083 |   0.527083 |   0.527083 |
| macro avg    |    0.528874 | 0.527083 |   0.527638 | 480        |
| weighted avg |    0.528874 | 0.527083 |   0.527638 | 480        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.527083 |
| precision_weighted | 0.528874 |
| recall_weighted    | 0.527083 |
| f1_weighted        | 0.527638 |
| roc_auc_ovr        | 0.790475 |
| log_loss           | 1.06877  |
| gini_normalized    | 0.580949 |
| ks_test_clase_0    | 0.408333 |
| ks_test_clase_1    | 0.525    |
| ks_test_clase_2    | 0.388889 |
| ks_test_clase_3    | 0.494444 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       58 |       20 |       17 |       25 |
| Real 1 |       20 |       68 |       25 |        7 |
| Real 2 |       18 |       17 |       59 |       26 |
| Real 3 |       23 |        6 |       23 |       68 |


### 8.1.2 Random Forest Classifier

| parámetro         | valor   |
|:------------------|:--------|
| max_depth         | 10      |
| max_features      | sqrt    |
| min_samples_leaf  | 2       |
| min_samples_split | 2       |
| n_estimators      | 500     |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.390244 | 0.4      |   0.395062 | 120        |
| 1            |    0.57377  | 0.583333 |   0.578512 | 120        |
| 2            |    0.445545 | 0.375    |   0.40724  | 120        |
| 3            |    0.514925 | 0.575    |   0.543307 | 120        |
| accuracy     |    0.483333 | 0.483333 |   0.483333 |   0.483333 |
| macro avg    |    0.481121 | 0.483333 |   0.48103  | 480        |
| weighted avg |    0.481121 | 0.483333 |   0.48103  | 480        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.483333 |
| precision_weighted | 0.481121 |
| recall_weighted    | 0.483333 |
| f1_weighted        | 0.48103  |
| roc_auc_ovr        | 0.751476 |
| log_loss           | 1.24126  |
| gini_normalized    | 0.502951 |
| ks_test_clase_0    | 0.302778 |
| ks_test_clase_1    | 0.522222 |
| ks_test_clase_2    | 0.327778 |
| ks_test_clase_3    | 0.45     |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       48 |       22 |       20 |       30 |
| Real 1 |       23 |       70 |       21 |        6 |
| Real 2 |       25 |       21 |       45 |       29 |
| Real 3 |       27 |        9 |       15 |       69 |

### 8.1.3 Gradient Boosting Classifier

| parámetro         | valor   |
|:------------------|:--------|
| learning_rate     | 0.01    |
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 30      |
| min_samples_split | 2       |
| n_estimators      | 100     |
| subsample         | 1.0     |

|              |   precision |   recall |   f1-score |   support |
|:-------------|------------:|---------:|-----------:|----------:|
| 0            |    0.431818 | 0.475    |   0.452381 |     120   |
| 1            |    0.585586 | 0.541667 |   0.562771 |     120   |
| 2            |    0.45045  | 0.416667 |   0.4329   |     120   |
| 3            |    0.539683 | 0.566667 |   0.552846 |     120   |
| accuracy     |    0.5      | 0.5      |   0.5      |       0.5 |
| macro avg    |    0.501884 | 0.5      |   0.500224 |     480   |
| weighted avg |    0.501884 | 0.5      |   0.500224 |     480   |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.5      |
| precision_weighted | 0.501884 |
| recall_weighted    | 0.5      |
| f1_weighted        | 0.500224 |
| roc_auc_ovr        | 0.751817 |
| log_loss           | 1.25756  |
| gini_normalized    | 0.503634 |
| ks_test_clase_0    | 0.35     |
| ks_test_clase_1    | 0.480556 |
| ks_test_clase_2    | 0.344444 |
| ks_test_clase_3    | 0.480556 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       57 |       20 |       20 |       23 |
| Real 1 |       26 |       65 |       24 |        5 |
| Real 2 |       21 |       19 |       50 |       30 |
| Real 3 |       28 |        7 |       17 |       68 |

### 8.1.4 Naive Bayes

| parámetro     |   valor |
|:--------------|--------:|
| var_smoothing |   1e-09 |


|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.338129 | 0.391667 |   0.362934 | 120        |
| 1            |    0.315412 | 0.733333 |   0.441103 | 120        |
| 2            |    0.363636 | 0.1      |   0.156863 | 120        |
| 3            |    0.482759 | 0.116667 |   0.187919 | 120        |
| accuracy     |    0.335417 | 0.335417 |   0.335417 |   0.335417 |
| macro avg    |    0.374984 | 0.335417 |   0.287205 | 480        |
| weighted avg |    0.374984 | 0.335417 |   0.287205 | 480        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.335417 |
| precision_weighted | 0.374984 |
| recall_weighted    | 0.335417 |
| f1_weighted        | 0.287205 |
| roc_auc_ovr        | 0.616916 |
| log_loss           | 6.40477  |
| gini_normalized    | 0.233831 |
| ks_test_clase_0    | 0.186111 |
| ks_test_clase_1    | 0.266667 |
| ks_test_clase_2    | 0.163889 |
| ks_test_clase_3    | 0.216667 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       47 |       65 |        5 |        3 |
| Real 1 |       25 |       88 |        6 |        1 |
| Real 2 |       32 |       65 |       12 |       11 |
| Real 3 |       35 |       61 |       10 |       14 |

### 8.1.5 XGB Classifier

| parámetro          | valor          |
|:-------------------|:---------------|
| objective          | multi:softprob |
| enable_categorical | False          |
| eval_metric        | merror         |
| learning_rate      | 0.1            |
| missing            | nan            |
| n_estimators       | 5000           |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.445378 | 0.441667 |   0.443515 | 120        |
| 1            |    0.603604 | 0.558333 |   0.580087 | 120        |
| 2            |    0.48     | 0.5      |   0.489796 | 120        |
| 3            |    0.536    | 0.558333 |   0.546939 | 120        |
| accuracy     |    0.514583 | 0.514583 |   0.514583 |   0.514583 |
| macro avg    |    0.516245 | 0.514583 |   0.515084 | 480        |
| weighted avg |    0.516245 | 0.514583 |   0.515084 | 480        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.514583 |
| precision_weighted | 0.516245 |
| recall_weighted    | 0.514583 |
| f1_weighted        | 0.515084 |
| roc_auc_ovr        | 0.762303 |
| log_loss           | 1.4775   |
| gini_normalized    | 0.524606 |
| ks_test_clase_0    | 0.333333 |
| ks_test_clase_1    | 0.494444 |
| ks_test_clase_2    | 0.380556 |
| ks_test_clase_3    | 0.505556 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       53 |       22 |       14 |       31 |
| Real 1 |       22 |       67 |       26 |        5 |
| Real 2 |       22 |       16 |       60 |       22 |
| Real 3 |       22 |        6 |       25 |       67 |

## 8.2 Modelado utilizando valores de series en chunks de 100

### 8.2.1 Logistic Regression

| parámetro   | valor   |
|:------------|:--------|
| C           | 0.001   |
| penalty     | l2      |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.236749 | 0.223333 |   0.229846 |  300        |
| 1            |    0.27551  | 0.27     |   0.272727 |  300        |
| 2            |    0.257329 | 0.263333 |   0.260297 |  300        |
| 3            |    0.256329 | 0.27     |   0.262987 |  300        |
| accuracy     |    0.256667 | 0.256667 |   0.256667 |    0.256667 |
| macro avg    |    0.256479 | 0.256667 |   0.256464 | 1200        |
| weighted avg |    0.256479 | 0.256667 |   0.256464 | 1200        |

| metric             |       value |
|:-------------------|------------:|
| accuracy           | 0.256667    |
| precision_weighted | 0.256479    |
| recall_weighted    | 0.256667    |
| f1_weighted        | 0.256464    |
| roc_auc_ovr        | 0.500283    |
| log_loss           | 1.39063     |
| gini_normalized    | 0.000566667 |
| ks_test_clase_0    | 0.0711111   |
| ks_test_clase_1    | 0.06        |
| ks_test_clase_2    | 0.0388889   |
| ks_test_clase_3    | 0.03        |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.236749 | 0.223333 |   0.229846 |  300        |
| 1            |    0.27551  | 0.27     |   0.272727 |  300        |
| 2            |    0.257329 | 0.263333 |   0.260297 |  300        |
| 3            |    0.256329 | 0.27     |   0.262987 |  300        |
| accuracy     |    0.256667 | 0.256667 |   0.256667 |    0.256667 |
| macro avg    |    0.256479 | 0.256667 |   0.256464 | 1200        |
| weighted avg |    0.256479 | 0.256667 |   0.256464 | 1200        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.333333 |
| precision_weighted | 0.340975 |
| recall_weighted    | 0.333333 |
| f1_weighted        | 0.335172 |



### 8.2.2 Random Forest Classifier

| parámetro         | valor   |
|:------------------|:--------|
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 2       |
| min_samples_split | 10      |
| n_estimators      | 500     |


|              |   precision |   recall |   f1-score |   support |
|:-------------|------------:|---------:|-----------:|----------:|
| 0            |    0.407801 | 0.383333 |   0.395189 |   300     |
| 1            |    0.640678 | 0.63     |   0.635294 |   300     |
| 2            |    0.402214 | 0.363333 |   0.381786 |   300     |
| 3            |    0.480114 | 0.563333 |   0.518405 |   300     |
| accuracy     |    0.485    | 0.485    |   0.485    |     0.485 |
| macro avg    |    0.482702 | 0.485    |   0.482669 |  1200     |
| weighted avg |    0.482702 | 0.485    |   0.482669 |  1200     |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.485    |
| precision_weighted | 0.482702 |
| recall_weighted    | 0.485    |
| f1_weighted        | 0.482669 |
| roc_auc_ovr        | 0.73496  |
| log_loss           | 1.20453  |
| gini_normalized    | 0.46992  |
| ks_test_clase_0    | 0.246667 |
| ks_test_clase_1    | 0.546667 |
| ks_test_clase_2    | 0.266667 |
| ks_test_clase_3    | 0.44     |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      115 |       63 |       53 |       69 |
| Real 1 |       46 |      189 |       40 |       25 |
| Real 2 |       68 |       34 |      109 |       89 |
| Real 3 |       53 |        9 |       69 |      169 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.566667 |
| precision_weighted | 0.565486 |
| recall_weighted    | 0.566667 |
| f1_weighted        | 0.563655 |

### 8.2.3 Gradient Boosting Classifier

| parámetro         | valor   |
|:------------------|:--------|
| learning_rate     | 0.1     |
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 30      |
| min_samples_split | 2       |
| n_estimators      | 100     |
| subsample         | 1.0     |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.422222 | 0.443333 |   0.43252  |  300        |
| 1            |    0.732    | 0.61     |   0.665455 |  300        |
| 2            |    0.402299 | 0.466667 |   0.432099 |  300        |
| 3            |    0.498258 | 0.476667 |   0.487223 |  300        |
| accuracy     |    0.499167 | 0.499167 |   0.499167 |    0.499167 |
| macro avg    |    0.513695 | 0.499167 |   0.504324 | 1200        |
| weighted avg |    0.513695 | 0.499167 |   0.504324 | 1200        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.499167 |
| precision_weighted | 0.513695 |
| recall_weighted    | 0.499167 |
| f1_weighted        | 0.504324 |
| roc_auc_ovr        | 0.746159 |
| log_loss           | 1.19023  |
| gini_normalized    | 0.492319 |
| ks_test_clase_0    | 0.272222 |
| ks_test_clase_1    | 0.563333 |
| ks_test_clase_2    | 0.301111 |
| ks_test_clase_3    | 0.416667 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      133 |       48 |       65 |       54 |
| Real 1 |       53 |      183 |       46 |       18 |
| Real 2 |       73 |       15 |      140 |       72 |
| Real 3 |       56 |        4 |       97 |      143 |


| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.533333 |
| precision_weighted | 0.557202 |
| recall_weighted    | 0.533333 |
| f1_weighted        | 0.540249 |

### 8.2.4 Naive Bayes

| parámetro     |   valor |
|:--------------|--------:|
| var_smoothing |   1e-09 |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.316327 | 0.103333 |   0.155779 |  300        |
| 1            |    0.321823 | 0.776667 |   0.455078 |  300        |
| 2            |    0.351145 | 0.153333 |   0.213457 |  300        |
| 3            |    0.327935 | 0.27     |   0.296161 |  300        |
| accuracy     |    0.325833 | 0.325833 |   0.325833 |    0.325833 |
| macro avg    |    0.329307 | 0.325833 |   0.280119 | 1200        |
| weighted avg |    0.329307 | 0.325833 |   0.280119 | 1200        |

| metric             |     value |
|:-------------------|----------:|
| accuracy           |  0.325833 |
| precision_weighted |  0.329307 |
| recall_weighted    |  0.325833 |
| f1_weighted        |  0.280119 |
| roc_auc_ovr        |  0.588748 |
| log_loss           | 20.8603   |
| gini_normalized    |  0.177495 |
| ks_test_clase_0    |  0.185556 |
| ks_test_clase_1    |  0.242222 |
| ks_test_clase_2    |  0.117778 |
| ks_test_clase_3    |  0.115556 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |       31 |      164 |       29 |       76 |
| Real 1 |       13 |      233 |       27 |       27 |
| Real 2 |       20 |      171 |       46 |       63 |
| Real 3 |       34 |      156 |       29 |       81 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.308333 |
| precision_weighted | 0.302306 |
| recall_weighted    | 0.308333 |
| f1_weighted        | 0.241931 |

### 8.2.5 XGB Classifier

| parámetro             | valor          |
|:----------------------|:---------------|
| objective             | multi:softprob |
| early_stopping_rounds | 500            |
| enable_categorical    | False          |
| eval_metric           | auc            |
| learning_rate         | 0.1            |
| missing               | nan            |
| n_estimators          | 4000           |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.444816 | 0.443333 |   0.444073 |  300       |
| 1            |    0.732824 | 0.64     |   0.683274 |  300       |
| 2            |    0.412698 | 0.419355 |   0.416    |  310       |
| 3            |    0.5      | 0.556667 |   0.526814 |  300       |
| accuracy     |    0.51405  | 0.51405  |   0.51405  |    0.51405 |
| macro avg    |    0.522585 | 0.514839 |   0.51754  | 1210       |
| weighted avg |    0.521677 | 0.51405  |   0.516701 | 1210       |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.51405  |
| precision_weighted | 0.521677 |
| recall_weighted    | 0.51405  |
| f1_weighted        | 0.516701 |
| roc_auc_ovr        | 0.767521 |
| log_loss           | 1.12188  |
| gini_normalized    | 0.535042 |
| ks_test_clase_0    | 0.344286 |
| ks_test_clase_1    | 0.597143 |
| ks_test_clase_2    | 0.302043 |
| ks_test_clase_3    | 0.459304 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      133 |       45 |       71 |       51 |
| Real 1 |       49 |      192 |       37 |       22 |
| Real 2 |       69 |       17 |      130 |       94 |
| Real 3 |       48 |        8 |       77 |      167 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.528926 |
| precision_weighted | 0.537967 |
| recall_weighted    | 0.528926 |
| f1_weighted        | 0.532205 |

## 8.3 Modelado utilizando valores de series en chunks de 5

### 8.3.1 Logistic Regression

| parámetro   | valor   |
|:------------|:--------|
| C           | 0.0001  |
| penalty     | l2      |

|              |   precision |    recall |   f1-score |      support |
|:-------------|------------:|----------:|-----------:|-------------:|
| 0            |    0.284611 | 0.270333  |  0.277289  |  6000        |
| 1            |    0.253881 | 0.324333  |  0.284815  |  6000        |
| 2            |    0.244994 | 0.0346667 |  0.0607388 |  6000        |
| 3            |    0.247267 | 0.403333  |  0.306581  |  6000        |
| accuracy     |    0.258167 | 0.258167  |  0.258167  |     0.258167 |
| macro avg    |    0.257688 | 0.258167  |  0.232356  | 24000        |
| weighted avg |    0.257688 | 0.258167  |  0.232356  | 24000        |

| metric             |     value |
|:-------------------|----------:|
| accuracy           | 0.258167  |
| precision_weighted | 0.257688  |
| recall_weighted    | 0.258167  |
| f1_weighted        | 0.232356  |
| roc_auc_ovr        | 0.509649  |
| log_loss           | 1.38628   |
| gini_normalized    | 0.0192987 |
| ks_test_clase_0    | 0.0627778 |
| ks_test_clase_1    | 0.0753889 |
| ks_test_clase_2    | 0.0179444 |
| ks_test_clase_3    | 0.0317778 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |     1622 |     1865 |      223 |     2290 |
| Real 1 |     1243 |     1946 |      210 |     2601 |
| Real 2 |     1586 |     1730 |      208 |     2476 |
| Real 3 |     1248 |     2124 |      208 |     2420 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.266667 |
| precision_weighted | 0.241029 |
| recall_weighted    | 0.266667 |
| f1_weighted        | 0.21731  |

### 8.3.2 Random Forest Classifier

| parámetro         | valor   |
|:------------------|:--------|
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 2       |
| min_samples_split | 2       |
| n_estimators      | 350     |

|              |   precision |   recall |   f1-score |      support |
|:-------------|------------:|---------:|-----------:|-------------:|
| 0            |    0.343805 | 0.291833 |   0.315695 |  6000        |
| 1            |    0.498245 | 0.567667 |   0.530695 |  6000        |
| 2            |    0.291698 | 0.26     |   0.274938 |  6000        |
| 3            |    0.395954 | 0.443667 |   0.418455 |  6000        |
| accuracy     |    0.390792 | 0.390792 |   0.390792 |     0.390792 |
| macro avg    |    0.382425 | 0.390792 |   0.384946 | 24000        |
| weighted avg |    0.382425 | 0.390792 |   0.384946 | 24000        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.390792 |
| precision_weighted | 0.382425 |
| recall_weighted    | 0.390792 |
| f1_weighted        | 0.384946 |
| roc_auc_ovr        | 0.659797 |
| log_loss           | 1.27119  |
| gini_normalized    | 0.319593 |
| ks_test_clase_0    | 0.153889 |
| ks_test_clase_1    | 0.395667 |
| ks_test_clase_2    | 0.1075   |
| ks_test_clase_3    | 0.285111 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |     1751 |     1495 |     1245 |     1509 |
| Real 1 |      815 |     3406 |     1087 |      692 |
| Real 2 |     1366 |     1214 |     1560 |     1860 |
| Real 3 |     1161 |      721 |     1456 |     2662 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.508333 |
| precision_weighted | 0.492711 |
| recall_weighted    | 0.508333 |
| f1_weighted        | 0.492884 |

### 8.3.3 Gradient Boosting Classifier

| parámetro         | valor   |
|:------------------|:--------|
| learning_rate     | 0.1     |
| max_depth         | 5       |
| max_features      | log2    |
| min_samples_split | 10      |
| n_estimators      | 100     |
| subsample         | 1       |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.343348 | 0.2895   |   0.314133 |  6000       |
| 1            |    0.46613  | 0.559667 |   0.508634 |  6000       |
| 2            |    0.283394 | 0.2065   |   0.238912 |  6000       |
| 3            |    0.374202 | 0.459333 |   0.412421 |  6000       |
| accuracy     |    0.37875  | 0.37875  |   0.37875  |     0.37875 |
| macro avg    |    0.366769 | 0.37875  |   0.368525 | 24000       |
| weighted avg |    0.366769 | 0.37875  |   0.368525 | 24000       |

| metric             |     value |
|:-------------------|----------:|
| accuracy           | 0.37875   |
| precision_weighted | 0.366769  |
| recall_weighted    | 0.37875   |
| f1_weighted        | 0.368525  |
| roc_auc_ovr        | 0.642532  |
| log_loss           | 1.29391   |
| gini_normalized    | 0.285063  |
| ks_test_clase_0    | 0.153389  |
| ks_test_clase_1    | 0.356167  |
| ks_test_clase_2    | 0.0857778 |
| ks_test_clase_3    | 0.2645    |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |     1737 |     1605 |     1038 |     1620 |
| Real 1 |      843 |     3358 |      825 |      974 |
| Real 2 |     1320 |     1426 |     1239 |     2015 |
| Real 3 |     1159 |      815 |     1270 |     2756 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.491667 |
| precision_weighted | 0.468082 |
| recall_weighted    | 0.491667 |
| f1_weighted        | 0.46567  |

### 8.3.4 Naive Bayes

| parámetro     |   valor |
|:--------------|--------:|
| var_smoothing |   1e-09 |

|              |   precision |    recall |   f1-score |      support |
|:-------------|------------:|----------:|-----------:|-------------:|
| 0            |    0.290155 | 0.028     |  0.0510716 |  6000        |
| 1            |    0.263517 | 0.836667  |  0.400798  |  6000        |
| 2            |    0.281537 | 0.0818333 |  0.126808  |  6000        |
| 3            |    0.2874   | 0.125833  |  0.175032  |  6000        |
| accuracy     |    0.268083 | 0.268083  |  0.268083  |     0.268083 |
| macro avg    |    0.280652 | 0.268083  |  0.188427  | 24000        |
| weighted avg |    0.280652 | 0.268083  |  0.188427  | 24000        |

| metric             |     value |
|:-------------------|----------:|
| accuracy           | 0.268083  |
| precision_weighted | 0.280652  |
| recall_weighted    | 0.268083  |
| f1_weighted        | 0.188427  |
| roc_auc_ovr        | 0.527915  |
| log_loss           | 5.01168   |
| gini_normalized    | 0.0558292 |
| ks_test_clase_0    | 0.0701111 |
| ks_test_clase_1    | 0.107111  |
| ks_test_clase_2    | 0.0651111 |
| ks_test_clase_3    | 0.0232778 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      168 |     4564 |      475 |      793 |
| Real 1 |       63 |     5020 |      447 |      470 |
| Real 2 |      158 |     4742 |      491 |      609 |
| Real 3 |      190 |     4724 |      331 |      755 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.25     |
| precision_weighted | 0.14693  |
| recall_weighted    | 0.25     |
| f1_weighted        | 0.115846 |

### 8.3.5 XGB Classifier

| parámetro             | valor          |
|:----------------------|:---------------|
| objective             | multi:softprob |
| early_stopping_rounds | 500            |
| enable_categorical    | False          |
| eval_metric           | auc            |
| learning_rate         | 0.1            |
| missing               | nan            |
| n_estimators          | 4000           |


|              |   precision |   recall |   f1-score |      support |
|:-------------|------------:|---------:|-----------:|-------------:|
| 0            |    0.342726 | 0.249333 |   0.288664 |  6000        |
| 1            |    0.498062 | 0.578167 |   0.535133 |  6000        |
| 2            |    0.350038 | 0.295161 |   0.320266 |  6200        |
| 3            |    0.403559 | 0.514    |   0.452133 |  6000        |
| accuracy     |    0.408223 | 0.408223 |   0.408223 |     0.408223 |
| macro avg    |    0.398596 | 0.409165 |   0.399049 | 24200        |
| weighted avg |    0.398195 | 0.408223 |   0.398398 | 24200        |


| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.408223 |
| precision_weighted | 0.398195 |
| recall_weighted    | 0.408223 |
| f1_weighted        | 0.398398 |
| roc_auc_ovr        | 0.667674 |
| log_loss           | 1.30001  |
| gini_normalized    | 0.335349 |
| ks_test_clase_0    | 0.145802 |
| ks_test_clase_1    | 0.4105   |
| ks_test_clase_2    | 0.150387 |
| ks_test_clase_3    | 0.289844 |


|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |     1496 |     1430 |     1266 |     1808 |
| Real 1 |      664 |     3469 |     1136 |      731 |
| Real 2 |     1231 |     1120 |     1830 |     2019 |
| Real 3 |      974 |      946 |      996 |     3084 |


| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.512397 |
| precision_weighted | 0.509052 |
| recall_weighted    | 0.512397 |
| f1_weighted        | 0.472916 |


## 8.4 Modelado utilizando ingeniería de variables divida las series en chunks de 100

### 8.4.1 Logistic Regression

| parámetro   | valor   |
|:------------|:--------|
| C           | 0.0001  |
| penalty     | l2      |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.47512  | 0.493333 |   0.484056 |  600        |
| 1            |    0.654691 | 0.546667 |   0.595822 |  600        |
| 2            |    0.489028 | 0.52     |   0.504039 |  600        |
| 3            |    0.485893 | 0.516667 |   0.500808 |  600        |
| accuracy     |    0.519167 | 0.519167 |   0.519167 |    0.519167 |
| macro avg    |    0.526183 | 0.519167 |   0.521181 | 2400        |
| weighted avg |    0.526183 | 0.519167 |   0.521181 | 2400        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.519167 |
| precision_weighted | 0.526183 |
| recall_weighted    | 0.519167 |
| f1_weighted        | 0.521181 |
| roc_auc_ovr        | 0.783896 |
| log_loss           | 1.09042  |
| gini_normalized    | 0.567791 |
| ks_test_clase_0    | 0.401667 |
| ks_test_clase_1    | 0.548889 |
| ks_test_clase_2    | 0.402222 |
| ks_test_clase_3    | 0.441111 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      296 |       66 |       89 |      149 |
| Real 1 |      123 |      328 |      108 |       41 |
| Real 2 |       67 |       83 |      312 |      138 |
| Real 3 |      137 |       24 |      129 |      310 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.554167 |
| precision_weighted | 0.561159 |
| recall_weighted    | 0.554167 |
| f1_weighted        | 0.555268 |

### 8.4.2 Random Forest Classifier


| parámetro         | valor   |
|:------------------|:--------|
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 2       |
| min_samples_split | 10      |
| n_estimators      | 500     |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.463663 | 0.531667 |   0.495342 |  600       |
| 1            |    0.682828 | 0.563333 |   0.617352 |  600       |
| 2            |    0.475806 | 0.491667 |   0.483607 |  600       |
| 3            |    0.530988 | 0.528333 |   0.529657 |  600       |
| accuracy     |    0.52875  | 0.52875  |   0.52875  |    0.52875 |
| macro avg    |    0.538321 | 0.52875  |   0.531489 | 2400       |
| weighted avg |    0.538321 | 0.52875  |   0.531489 | 2400       |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.52875  |
| precision_weighted | 0.538321 |
| recall_weighted    | 0.52875  |
| f1_weighted        | 0.531489 |
| roc_auc_ovr        | 0.780963 |
| log_loss           | 1.16351  |
| gini_normalized    | 0.561925 |
| ks_test_clase_0    | 0.376111 |
| ks_test_clase_1    | 0.537778 |
| ks_test_clase_2    | 0.382222 |
| ks_test_clase_3    | 0.473889 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      319 |       62 |       93 |      126 |
| Real 1 |      119 |      338 |      110 |       33 |
| Real 2 |      109 |       75 |      295 |      121 |
| Real 3 |      141 |       20 |      122 |      317 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.545833 |
| precision_weighted | 0.557403 |
| recall_weighted    | 0.545833 |
| f1_weighted        | 0.548086 |

### 8.4.3 Gradient Boosting Classifier

| parámetro         | valor   |
|:------------------|:--------|
| learning_rate     | 0.01    |
| max_depth         | 20      |
| max_features      | sqrt    |
| min_samples_leaf  | 30      |
| min_samples_split | 2       |
| n_estimators      | 100     |
| subsample         | 1.0     |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.46495  | 0.541667 |   0.500385 |  600        |
| 1            |    0.681913 | 0.546667 |   0.606846 |  600        |
| 2            |    0.492823 | 0.515    |   0.503667 |  600        |
| 3            |    0.526138 | 0.52     |   0.523051 |  600        |
| accuracy     |    0.530833 | 0.530833 |   0.530833 |    0.530833 |
| macro avg    |    0.541456 | 0.530833 |   0.533487 | 2400        |
| weighted avg |    0.541456 | 0.530833 |   0.533487 | 2400        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.530833 |
| precision_weighted | 0.541456 |
| recall_weighted    | 0.530833 |
| f1_weighted        | 0.533487 |
| roc_auc_ovr        | 0.789092 |
| log_loss           | 1.19036  |
| gini_normalized    | 0.578184 |
| ks_test_clase_0    | 0.373333 |
| ks_test_clase_1    | 0.550556 |
| ks_test_clase_2    | 0.415    |
| ks_test_clase_3    | 0.485556 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      325 |       67 |       88 |      120 |
| Real 1 |      117 |      328 |      117 |       38 |
| Real 2 |       97 |       71 |      309 |      123 |
| Real 3 |      160 |       15 |      113 |      312 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.554167 |
| precision_weighted | 0.566695 |
| recall_weighted    | 0.554167 |
| f1_weighted        | 0.557091 |

### 8.4.4 Naive Bayes

| parámetro     |   valor |
|:--------------|--------:|
| var_smoothing |   1e-05 |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.409314 | 0.278333 |   0.331349 |  600        |
| 1            |    0.335532 | 0.678333 |   0.44898  |  600        |
| 2            |    0.310263 | 0.216667 |   0.255152 |  600        |
| 3            |    0.447222 | 0.268333 |   0.335417 |  600        |
| accuracy     |    0.360417 | 0.360417 |   0.360417 |    0.360417 |
| macro avg    |    0.375583 | 0.360417 |   0.342724 | 2400        |
| weighted avg |    0.375583 | 0.360417 |   0.342724 | 2400        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.360417 |
| precision_weighted | 0.375583 |
| recall_weighted    | 0.360417 |
| f1_weighted        | 0.342724 |
| roc_auc_ovr        | 0.649275 |
| log_loss           | 5.06678  |
| gini_normalized    | 0.29855  |
| ks_test_clase_0    | 0.23     |
| ks_test_clase_1    | 0.313889 |
| ks_test_clase_2    | 0.187222 |
| ks_test_clase_3    | 0.257778 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      167 |      266 |       90 |       77 |
| Real 1 |      100 |      407 |       35 |       58 |
| Real 2 |       47 |      359 |      130 |       64 |
| Real 3 |       94 |      181 |      164 |      161 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.383333 |
| precision_weighted | 0.420908 |
| recall_weighted    | 0.383333 |
| f1_weighted        | 0.364589 |

### 8.4.5 XGB Classifier

| parámetro             | valor          |
|:----------------------|:---------------|
| objective             | multi:softprob |
| early_stopping_rounds | 500            |
| enable_categorical    | False          |
| eval_metric           | auc            |
| learning_rate         | 0.1            |
| missing               | nan            |
| n_estimators          | 4000           |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.516447 | 0.523333 |   0.519868 |  600        |
| 1            |    0.688552 | 0.681667 |   0.685092 |  600        |
| 2            |    0.534314 | 0.536066 |   0.535188 |  610        |
| 3            |    0.557047 | 0.553333 |   0.555184 |  600        |
| accuracy     |    0.573444 | 0.573444 |   0.573444 |    0.573444 |
| macro avg    |    0.57409  | 0.5736   |   0.573833 | 2410        |
| weighted avg |    0.573925 | 0.573444 |   0.573673 | 2410        |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.573444 |
| precision_weighted | 0.573925 |
| recall_weighted    | 0.573444 |
| f1_weighted        | 0.573673 |
| roc_auc_ovr        | 0.824416 |
| log_loss           | 1.28027  |
| gini_normalized    | 0.648832 |
| ks_test_clase_0    | 0.459024 |
| ks_test_clase_1    | 0.611123 |
| ks_test_clase_2    | 0.447823 |
| ks_test_clase_3    | 0.500985 |

|        |   Pred 0 |   Pred 1 |   Pred 2 |   Pred 3 |
|:-------|---------:|---------:|---------:|---------:|
| Real 0 |      314 |      107 |       64 |      115 |
| Real 1 |       89 |      409 |       85 |       17 |
| Real 2 |       90 |       61 |      327 |      132 |
| Real 3 |      115 |       17 |      136 |      332 |

| metric             |    value |
|:-------------------|---------:|
| accuracy           | 0.593361 |
| precision_weighted | 0.594469 |
| recall_weighted    | 0.593361 |
| f1_weighted        | 0.593719 |

-->